{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junhuk1113/AIAD_weather/blob/master/custom_gan_3_1(cuda_and_torch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhCYZdjT-6T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPcLl7CSVcIN"
      },
      "outputs": [],
      "source": [
        "#import library\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image as Img\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "from skimage import io, transform\n",
        "import imageio\n",
        "import datetime\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "#import keras\n",
        "\n",
        "import keras \n",
        "from keras import Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras import Model, layers\n",
        "from keras.callbacks import *\n",
        "from keras.models import load_model, model_from_json\n",
        "from keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch and cuda import\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "call_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if call_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "8CxOfQtOVwnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test on torch bring GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KFn-6bQNV8aM",
        "outputId": "671be1c2-5834-42ad-8884-25e6405f14c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fXPtjqU-an8",
        "outputId": "db88d013-6477-4813-f5c6-2fe7888276d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"사용하는 Device : \", DEVICE)\n",
        "\n",
        "current_time = datetime.datetime.now() + datetime.timedelta(hours= 9)\n",
        "current_time = current_time.strftime('%Y-%m-%d-%H:%M')\n",
        "\n",
        "saved_loc = os.path.join('/content/drive/MyDrive/GAN_Result', current_time)\n",
        "if os.path.exists(saved_loc):\n",
        "    shutil.rmtree(saved_loc)\n",
        "os.mkdir(saved_loc)\n",
        "\n",
        "print(\"저장 위치: \", saved_loc)\n",
        "\n",
        "image_loc = os.path.join(saved_loc, \"images\")\n",
        "os.mkdir(image_loc)\n",
        "\n",
        "writer = SummaryWriter(saved_loc)\n",
        "\n",
        "EPOCHS = 32\n",
        "BATCH_SIZE = 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tLHd-wiXuPm",
        "outputId": "dc581ce4-044a-431a-a274-b5000e805792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용하는 Device :  cuda\n",
            "저장 위치:  /content/drive/MyDrive/GAN_Result/2022-10-07-17:35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "class CustomDataset(Dataset): \n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75],\n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "\n",
        "  # 총 데이터의 개수를 리턴\n",
        "  def __len__(self): \n",
        "    return len(self.x_data)\n",
        "\n",
        "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
        "  def __getitem__(self, idx): \n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "    return x, y\n",
        "dataset = CustomDataset()\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "model = torch.nn.Linear(3,1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    # print(batch_idx)\n",
        "    # print(samples)\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))\n",
        "Epoch\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mQPyKaNvV_4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 64\n",
        "DATA_DIR = '/content/drive/MyDrive/PBL_Shared_Data/202101cldcr200re64new.npy'\n",
        "X_train = np.load(DATA_DIR)\n",
        "print(f\"Shape of training data: {X_train.shape}\")\n",
        "print(f\"Data type: {type(X_train)}\")\n",
        "\n",
        "print(type(X_train[0][0][0][0]))\n",
        "\n",
        "#data = X_train.astype(np.float64)\n",
        "# = 255 * data\n",
        "#X_train = data.astype(np.uint8)\n",
        "random_image = random.randint(0, len(X_train))\n",
        "plt.imshow(X_train[random_image,0],cmap='gray',vmin=0,vmax=255)\n",
        "plt.title(f\"Training example #{random_image}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "laj3GujYX6Nh",
        "outputId": "4c983ff0-920a-4e1e-ff0c-91ba4320d3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (31, 24, 64, 64)\n",
            "Data type: <class 'numpy.ndarray'>\n",
            "<class 'numpy.uint8'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer code\n",
        "transformer = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\"\"\"\n",
        "class SimpleCustomBatch:\n",
        "    def __init__(self, data):\n",
        "        transposed_data = list(zip(*data))\n",
        "        self.inp = torch.stack(transposed_data[0], 0)\n",
        "        self.tgt = torch.stack(transposed_data[1], 0)\n",
        "\n",
        "    # custom memory pinning method on custom type\n",
        "    def pin_memory(self):\n",
        "        self.inp = self.inp.pin_memory()\n",
        "        self.tgt = self.tgt.pin_memory()\n",
        "        return self\n",
        "\n",
        "def collate_wrapper(batch):\n",
        "    return SimpleCustomBatch(batch)\n",
        "\n",
        "inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
        "tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
        "dataset = TensorDataset(inps, tgts)\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n",
        "                    pin_memory=True)\n",
        "\n",
        "for batch_ndx, sample in enumerate(loader):\n",
        "    print(sample.inp.is_pinned())\n",
        "    print(sample.tgt.is_pinned())\n",
        "    \"\"\"\n",
        "    "
      ],
      "metadata": {
        "id": "dkFE3QSHWQOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "10d9a157-1970-44e4-f667-603b5f71e597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass SimpleCustomBatch:\\n    def __init__(self, data):\\n        transposed_data = list(zip(*data))\\n        self.inp = torch.stack(transposed_data[0], 0)\\n        self.tgt = torch.stack(transposed_data[1], 0)\\n\\n    # custom memory pinning method on custom type\\n    def pin_memory(self):\\n        self.inp = self.inp.pin_memory()\\n        self.tgt = self.tgt.pin_memory()\\n        return self\\n\\ndef collate_wrapper(batch):\\n    return SimpleCustomBatch(batch)\\n\\ninps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\\ntgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\\ndataset = TensorDataset(inps, tgts)\\n\\nloader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\\n                    pin_memory=True)\\n\\nfor batch_ndx, sample in enumerate(loader):\\n    print(sample.inp.is_pinned())\\n    print(sample.tgt.is_pinned())\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading trainset, testset and trainloader, testloader\n",
        "class SimpleCustomBatch:\n",
        "    def __init__(self, data):\n",
        "        transposed_data = list(zip(*data))\n",
        "        self.inp = torch.stack(transposed_data[0], 0)\n",
        "        self.tgt = torch.stack(transposed_data[1], 0)\n",
        "\n",
        "    # custom memory pinning method on custom type\n",
        "    def pin_memory(self):\n",
        "        self.inp = self.inp.pin_memory()\n",
        "        self.tgt = self.tgt.pin_memory()\n",
        "        return self\n",
        "\n",
        "def collate_wrapper(batch):\n",
        "    return SimpleCustomBatch(batch)\n",
        "\n",
        "input = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
        "target = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
        "dataset = CustomDataset(inps, tgts)\n",
        "#dataset = CustomDataset(inps, tgts)\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n",
        "                    pin_memory=True)\n",
        "\n",
        "for batch_ndx, sample in enumerate(loader):\n",
        "    print(sample.inp.is_pinned())\n",
        "    print(sample.tgt.is_pinned())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "HkWJDimKo1PC",
        "outputId": "b00de50b-1924-474e-b125-281d6cc836f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-539c1ce2950a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0minps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m#dataset = CustomDataset(inps, tgts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample, label = next(iter(trainloader))\n",
        "\n",
        "# show grid image\n",
        "def imshow_grid(img):\n",
        "    img = torchvision.utils.make_grid(img.cpu().detach())\n",
        "    img = (img + 1) / 2\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    ax = plt.gca()\n",
        "    ax.axes.xaxis.set_visible(False)\n",
        "    ax.axes.yaxis.set_visible(False)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "imshow_grid(sample[0:8])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "gq-heA2yFcaj",
        "outputId": "544c23ae-b0f7-4093-ba2c-611405eaf8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b9876d165ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# show grid image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimshow_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator class\n",
        "class Dis_model(nn.Module):\n",
        "    def __init__(self, image_size, hidden_space):\n",
        "        super(Dis_model, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, 1),\n",
        "            nn.Sigmoid())\n",
        "    \n",
        "    def forward(self, input_x):\n",
        "        x = self.features(input_x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "KSlXrbKe06nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator class\n",
        "class Gen_model(nn.Module):\n",
        "    def __init__(self, latent_space, hidden_space, image_size):\n",
        "        super(Gen_model, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Linear(latent_space, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, hidden_space),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_space, image_size),\n",
        "            nn.Tanh())\n",
        "        \n",
        "    def forward(self, input_x):\n",
        "        x = self.features(input_x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "I9RmGzRH0Nbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_size = 784\n",
        "hidden_size = 256\n",
        "latent_size = 100\n",
        "\n",
        "Dis_net = Dis_model(image_size = im_size, hidden_space = hidden_size).to(DEVICE)\n",
        "Gen_net = Gen_model(image_size = im_size, hidden_space = hidden_size, latent_space = latent_size).to(DEVICE)\n",
        "\n",
        "d_optimizer = optim.Adam(Dis_net.parameters(), lr = 0.0002)\n",
        "g_optimizer = optim.Adam(Gen_net.parameters(), lr = 0.0002)\n",
        "\n",
        "fixed_noise = torch.randn(10, latent_size, 1, 1, device = DEVICE)\n"
      ],
      "metadata": {
        "id": "J-7ROVzJ0woo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "\n",
        "def train(generator, discriminator, train_loader, optimizer_d, optimizer_g):\n",
        "\n",
        "  # Train version\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "\n",
        "\n",
        "    for data, target in train_loader:\n",
        "\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "        # ==========================================#\n",
        "        # ==========Optimize discriminator==========#\n",
        "        # ==========================================#\n",
        "\n",
        "        # initialize discriminator optimizer\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Make noise samples for discriminator update\n",
        "        noise_samples_d = torch.randn(BATCH_SIZE, latent_size).to(DEVICE)\n",
        "\n",
        "        # real loss\n",
        "        discri_value = discriminator(data.view(-1, 28*28))\n",
        "        loss_real = -1 * torch.log(discri_value) # gradient ascent\n",
        "\n",
        "        # fake loss\n",
        "        gene_value = discriminator(generator(noise_samples_d))\n",
        "        loss_fake = -1 * torch.log(1.0 - gene_value) # gradient ascent\n",
        "\n",
        "        # Final loss\n",
        "        loss_d = (loss_real + loss_fake).mean()\n",
        "\n",
        "        loss_d.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "\n",
        "        # ========================================= #\n",
        "        # ==========Optimize generator============= #\n",
        "        # ========================================= #\n",
        "\n",
        "        # initialize generator optimizer\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        # Make noise samples for generator update\n",
        "        noise_samples_g = torch.randn(BATCH_SIZE, latent_size).to(DEVICE)\n",
        "\n",
        "        # calculate loss\n",
        "        fake_value = discriminator(generator(noise_samples_g))\n",
        "        loss_generator = -1 * torch.log(fake_value).mean() # provide much stronger gradients early in learning.\n",
        "        \n",
        "        loss_generator.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "    D_loss_epoch = torch.mean(torch.FloatTensor(D_losses))\n",
        "    G_loss_epoch = torch.mean(torch.FloatTensor(G_losses))\n",
        "    writer.add_scalars(\"Train\", {\"Average Discriminator loss per epoch\" : D_loss_epoch.item(),\n",
        "                                 \"Average Generator loss per epoch\" : G_loss_epoch.item()}, epoch)\n",
        "\n"
      ],
      "metadata": {
        "id": "KcDKyLnd1Ugg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    train(Gen_net, Dis_net, trainloader, d_optimizer, g_optimizer)\n",
        "\n",
        "    fixed_noise_generation = Gen_net(fixed_noise.view(-1, latent_size))\n",
        "    torchvision.utils.save_image(fixed_noise_generation.detach(),\n",
        "                                 '%s/fixed_noise_generation_epoch_%03d.png' % (image_loc, epoch), normalize = True)\n",
        "\n",
        "    if (epoch+1)%20 == 0:\n",
        "        print('epoch %i / %i' % (epoch+1, EPOCHS))\n",
        "        \n",
        "        noise_sam = torch.randn(16, latent_size).to(DEVICE)\n",
        "        imshow_grid(Gen_net(noise_sam).view(-1, 1, 28, 28))\n",
        "        print(\"\\n\")\n",
        "\n",
        "writer.close()\n"
      ],
      "metadata": {
        "id": "GOwRFwpB4wst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AaN8yK52VqQ6"
      }
    }
  ]
}