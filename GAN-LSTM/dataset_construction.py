# -*- coding: utf-8 -*-
"""IntegrateCloudCoverateRate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nWKVMIJ7gs6tcelralJEelwt-8U7fXa0
"""

# Load features and prepare the dataset for LSTM
features_df = pd.read_csv("/content/drive/MyDrive/PBL_Shared_Data/Generated_Images_and_Features/features.csv")

# Assume additional meteorological data is available
weather_data = pd.read_csv("/content/drive/MyDrive/PBL_Shared_Data/weather_data.csv")

# Combine datasets by timestamp if necessary, otherwise directly use features_df
combined_data = pd.merge(features_df, weather_data, on="timestamp", how="inner")

# Create sequences from combined data
def create_sequences(data, n_steps):
    X, y = [], []
    for i in range(len(data) - n_steps):
        X.append(data.iloc[i:i+n_steps].drop(['target', 'timestamp', 'image_path'], axis=1).values)
        y.append(data.iloc[i + n_steps]['target'])
    return np.array(X), np.array(y)

n_steps = 10
X, y = create_sequences(combined_data, n_steps)

# Normalize the data
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)

# Split the data into training and validation sets
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
